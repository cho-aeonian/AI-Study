{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7006d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8835f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'happy', 'relaxed', 'sad']\n"
     ]
    }
   ],
   "source": [
    "# 0: 'angry',\n",
    "# 1: 'happy',\n",
    "# 2: relaxed',\n",
    "# 3: 'sad'\n",
    "\n",
    "import os\n",
    "driver_image_path = r'C:\\Users\\U2SR\\Desktop\\Udemy\\tensorflow-cnn\\Dog Emotion'\n",
    "class_names = sorted(os.listdir(driver_image_path))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd53b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 440, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "imageee = cv2.imread(r'C:\\Users\\U2SR\\Desktop\\Udemy\\tensorflow-cnn\\Dog Emotion\\angry\\0aNyXBrmNA7XdefwHvgO2n1rnpqQAp885.jpg')\n",
    "imageee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7f2b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images : 3975, Total labels : 3975\n"
     ]
    }
   ],
   "source": [
    "img_size = (200, 200, 3)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    images_files_folder_name = os.path.join(driver_image_path, class_name)\n",
    "    if os.path.isdir(images_files_folder_name):\n",
    "        for image_name in os.listdir(images_files_folder_name):\n",
    "            if image_name.lower().endswith('.jpg'):\n",
    "                image_full_path = os.path.join(images_files_folder_name, image_name)\n",
    "                \n",
    "                img = cv2.imread(image_full_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img_cvt = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_resized = cv2.resize(img_cvt, img_size[:2])\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                labels.append(class_names.index(class_name))\n",
    "\n",
    "print(f\"Total images : {len(images)}, Total labels : {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107387f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ad50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_val , y_train , y_val = train_test_split(images , labels , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2b0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(factor=0.05),             #랜덤 회전\n",
    "    tf.keras.layers.RandomFlip(mode='horizontal'),           #랜덤 수평 플립\n",
    "    tf.keras.layers.RandomContrast(factor=0.2),              #랜덤 대비 조정\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a38ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 크기를 지정된 크기로 조정해주는 함수\n",
    "def preprocessing_image(image , label):\n",
    "  image = tf.image.resize(image , img_size[:2])\n",
    "  return image , label\n",
    "\n",
    "#이미지에 이미지 증강을 적용해주는 함수\n",
    "def augment_image(image , label):\n",
    "  image = data_augmentation(image)\n",
    "  return image , label\n",
    "\n",
    "#이미지와 레이블을 tensorflow dataset으로 변환하고, 전처리 및 증강을 적용하여 배치와 프리패칭을 설정하는 함수\n",
    "def create_tensorflow_dataset(images ,labels , batch_size = 32 , buffer_size = 1000 , augment = False):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((images , labels))\n",
    "  dataset = dataset.map(preprocessing_image , num_parallel_calls = tf.data.AUTOTUNE)\n",
    "  if augment:\n",
    "    dataset = dataset.map(augment_image , num_parallel_calls = tf.data.AUTOTUNE)\n",
    "  dataset = dataset.shuffle(buffer_size)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35949714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU 탐색\n",
    "    print('Running on TPU:', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    global_batch_size = 32 * tpu_strategy.num_replicas_in_sync\n",
    "else:\n",
    "    global_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "094172ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_tensorflow_dataset(X_train , y_train , batch_size = global_batch_size , buffer_size = len(X_train) , augment = True)\n",
    "val_dataset = create_tensorflow_dataset(X_val , y_val , batch_size = global_batch_size , buffer_size = len(X_val) , augment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7ae6134",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tpu_strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtpu_strategy\u001b[49m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      5\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39mimg_size),\n\u001b[0;32m      6\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRescaling(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;28mlen\u001b[39m(class_names), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m     ])\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tpu_strategy' is not defined"
     ]
    }
   ],
   "source": [
    "img_size = (200, 200, 3)\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=img_size),\n",
    "        tf.keras.layers.Rescaling(scale=1./255),\n",
    "\n",
    "        tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(train_dataset, epochs=100, validation_data=val_dataset, callbacks=[early_stopping_cb])\n",
    "\n",
    "model.save('my_custom_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a3404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
