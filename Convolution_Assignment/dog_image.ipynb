{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow랑 keras 충돌 방지 위해서 기존의 keras 삭제\n",
    "!pip uninstall -y keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서플로우 설치\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731742a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#구글 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5376bd70",
   "metadata": {},
   "source": [
    "### 4가지 카테고리에 해당하는 클래스 이름을 폴더에서 읽어와 레이블로 사용하기 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angry : angry\n",
    "# happy : happy\n",
    "# relaxed : relaxed\n",
    "# sad : sad\n",
    "\n",
    "import os\n",
    "driver_image_path = '/content/drive/MyDrive/Dog Emotion'\n",
    "class_names = sorted(os.listdir(driver_image_path))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openCV 설치\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9eab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 크기 확인하기\n",
    "import cv2\n",
    "image = cv2.imread('/content/drive/MyDrive/Dog Emotion/angry/09dUVMcjCDfOtbeYDQg5Fvu3GPHWJg811.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5b28b",
   "metadata": {},
   "source": [
    "### OpenCV로 불러온 이미지의 파일 경로를 images 리스트에 넣어주고 인코딩한 레이블을 각 이미지에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "resize_size = (200, 200)\n",
    "img_size = (200, 200, 3)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    images_files_folder_name = os.path.join(driver_image_path, class_name)\n",
    "    if os.path.isdir(images_files_folder_name):\n",
    "        for image_name in os.listdir(images_files_folder_name):\n",
    "            if image_name.endswith('.jpg'):\n",
    "                image_full_path = os.path.join(images_files_folder_name, image_name)\n",
    "                img = cv2.imread(image_full_path)\n",
    "\n",
    "                if img is not None:\n",
    "                    img_resized = cv2.resize(img, resize_size)\n",
    "                    img_cvt = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    images.append(img_cvt)\n",
    "                    labels.append(class_names.index(class_name))\n",
    "                else:\n",
    "                    print(f\"읽기 실패: {image_full_path}\")\n",
    "\n",
    "print(f\"Total images : {len(images)} , Total labels : {len(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319c8b2",
   "metadata": {},
   "source": [
    "### 성능 최적화를 위해 이미지와 마스크 리스트를 넘파이 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78a7ae1",
   "metadata": {},
   "source": [
    "### images , labels 리스트를 x_train 과 x_test로 분할(Train에 80%, Test에 20% 할당)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test , y_train , y_test = train_test_split(images , labels , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115feb1f",
   "metadata": {},
   "source": [
    "### 랜덤회전 , 랜덤 수평플립, 랜덤 대비 조정 3가지 데이터 증강 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    #랜덤 회전\n",
    "    tf.keras.layers.RandomRotation(factor=0.05),\n",
    "    #랜덤 수평 플립\n",
    "    tf.keras.layers.RandomFlip(mode='horizontal'),\n",
    "    #랜덤 대비 조정\n",
    "    tf.keras.layers.RandomContrast(factor=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad13d1e",
   "metadata": {},
   "source": [
    "### 차례대로 이미지 크기를 지정된 크기로 조정해주는 전처리/이미지 증강 함수, 이미지와 레이블을 TensorFlow 데이터셋으로 변환하고, 전처리 및 증강을 적용하여 배치와 프리패칭을 설정하는 Tensorflow 데이터셋 생성 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f92b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지를 지정한 크기로 변환해주는 함수\n",
    "def preprocessing_image(image , label):\n",
    "  image = tf.image.resize(image , img_size[:2])\n",
    "  return image , label\n",
    "\n",
    "#이미지 증강을 적용해주는 함수\n",
    "def augment_image(image , label):\n",
    "  image = data_augmentation(image)\n",
    "  return image , label\n",
    "\n",
    "#이미지와 레이블을 tensorflow dataset으로 변환하고, 전처리 및 증강을 적용하여 배치와 프리패칭을 설정하는 함수\n",
    "def create_tensorflow_dataset(images ,labels , batch_size = 32 , buffer_size = 1000 , augment = False):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((images , labels))\n",
    "  dataset = dataset.map(preprocessing_image , num_parallel_calls = tf.data.AUTOTUNE)\n",
    "  if augment:\n",
    "    dataset = dataset.map(augment_image , num_parallel_calls = tf.data.AUTOTUNE)\n",
    "  dataset = dataset.shuffle(buffer_size)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81755ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9adf06",
   "metadata": {},
   "source": [
    "### 앞서 정의한 TensorFlow Dataset 함수를 이용하여 Train_dataset 및 Test_dataset 데이터셋 생성(Train_dataset에만 데이터 증강 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e108e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = create_tensorflow_dataset(x_train , y_train , batch_size = global_batch_size , buffer_size = len(x_train) , augment = True)\n",
    "val_dataset = create_tensorflow_dataset(x_test , y_test , batch_size = global_batch_size , buffer_size = len(x_test) , augment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef826c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TPU 있으면 TPU, 없으면 CPU/GPU 선택\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    print(\"TPU 사용:\", resolver.master())\n",
    "except Exception:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    print(\"TPU 없음, 기본 전략 사용:\", type(strategy))\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "])\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, [img_size[0], img_size[1]])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    return image, label\n",
    "\n",
    "def create_tensorflow_dataset(images, labels, batch_size, buffer_size, augment_flag=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    ds = ds.shuffle(buffer_size)\n",
    "    ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if augment_flag:\n",
    "        ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "global_batch_size = 32\n",
    "\n",
    "train_dataset = create_tensorflow_dataset(x_train, y_train,\n",
    "                                          batch_size=global_batch_size,\n",
    "                                          buffer_size=len(x_train),\n",
    "                                          augment_flag=True)\n",
    "val_dataset = create_tensorflow_dataset(x_test, y_test,\n",
    "                                        batch_size=global_batch_size,\n",
    "                                        buffer_size=len(x_test),\n",
    "                                        augment_flag=False)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=img_size),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=3, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Conv2D(256, kernel_size=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, kernel_size=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Conv2D(512, kernel_size=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "#학습\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=150,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping_cb]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
